---
title: "A two-stage expert-guided reinforcement learning controller training strategy for large time-delay systems"
collection: publications
category: manuscripts
permalink: /publication/2025-10-01-Shou2025
excerpt: The control of large time-delay systems presents a considerable challenge and practical necessity. Applying deep reinforcement learning (DRL) controllers for such systems encounters training difficulties due to the delayed rewards during the training process. Multi-stage training via incrementally increasing time delay is time-consuming and lacks robustness. To address these issues, we develop a two-stage expert-guided training framework for DRL controllers, where a Proportional-Integral-Derivative (PID) controller is adopted as an expert to accelerate the training procedure. A reference control variable trajectory generated by the PID controller and a hypothetical superior PID controller is utilized to calculate the rewards for the DRL controller during the stages of learning the expert and surpassing the expert, respectively. Two case studies demonstrate the availability and efficiency of the proposed strategy. For the industrial case study with a time delay of 264.8 s, the proposed strategy effectively trains DRL controllers, which perform better than PID controllers.
date: 2025-10-01
venue: 'Computers \& Chemical Engineering'
slidesurl: 'http://nicolashong.github.io/files/slides/Shou2025.pdf'
paperurl: 'http://nicolashong.github.io/files/papers/Shou2025.pdf'
bibtexurl: 'http://nicolashong.github.io/files/bibtex/Shou2025.bib'
citation: '10.1016/j.compchemeng.2025.109250'
---

The control of large time-delay systems presents a considerable challenge and practical necessity. Applying deep reinforcement learning (DRL) controllers for such systems encounters training difficulties due to the delayed rewards during the training process. Multi-stage training via incrementally increasing time delay is time-consuming and lacks robustness. To address these issues, we develop a two-stage expert-guided training framework for DRL controllers, where a Proportional-Integral-Derivative (PID) controller is adopted as an expert to accelerate the training procedure. A reference control variable trajectory generated by the PID controller and a hypothetical superior PID controller is utilized to calculate the rewards for the DRL controller during the stages of learning the expert and surpassing the expert, respectively. Two case studies demonstrate the availability and efficiency of the proposed strategy. For the industrial case study with a time delay of 264.8 s, the proposed strategy effectively trains DRL controllers, which perform better than PID controllers.
